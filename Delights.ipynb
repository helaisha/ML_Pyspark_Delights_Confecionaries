{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pyspark ML for Delights Confectionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('Delights').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read The dataset\n",
    "df = spark.read.csv('delight_confect.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------------+-------+-----+---------+\n",
      "|_c0| city|         Item|country|month|    sales|\n",
      "+---+-----+-------------+-------+-----+---------+\n",
      "|  0|Abuja|  Butter Cake|Nigeria|    1| 723266.0|\n",
      "|  1|Abuja|  Butter Cake|Nigeria|    2| 630520.0|\n",
      "|  2|Abuja|  Butter Cake|Nigeria|    3| 692946.0|\n",
      "|  3|Abuja|  Butter Cake|Nigeria|    4| 714788.0|\n",
      "|  4|Abuja|  Butter Cake|Nigeria|    5| 720920.0|\n",
      "|  5|Abuja|  Butter Cake|Nigeria|    6| 553146.0|\n",
      "|  6|Abuja|  Butter Cake|Nigeria|    7| 742040.0|\n",
      "|  7|Abuja|  Butter Cake|Nigeria|    8| 944060.0|\n",
      "|  8|Abuja|  Butter Cake|Nigeria|    9| 867996.0|\n",
      "|  9|Abuja|  Butter Cake|Nigeria|   10| 831078.0|\n",
      "| 10|Abuja|  Butter Cake|Nigeria|   11| 747806.0|\n",
      "| 11|Abuja|  Butter Cake|Nigeria|   12| 790578.0|\n",
      "| 12|Abuja|Club Sandwich|Nigeria|    7|    560.0|\n",
      "| 13|Abuja|Club Sandwich|Nigeria|    8|      0.0|\n",
      "| 14|Abuja|Club Sandwich|Nigeria|    9|      0.0|\n",
      "| 15|Abuja|Club Sandwich|Nigeria|   10|    460.0|\n",
      "| 16|Abuja|Club Sandwich|Nigeria|   11|   2908.0|\n",
      "| 17|Abuja|Club Sandwich|Nigeria|   12|   2536.0|\n",
      "| 18|Abuja|     Doughnut|Nigeria|    1|1546638.0|\n",
      "| 19|Abuja|     Doughnut|Nigeria|    2|1255042.0|\n",
      "+---+-----+-------------+-------+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- Item: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0', 'city', 'Item', 'country', 'month', 'sales']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Handling Categorical Features\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------------+-------+-----+---------+-----+-----+--------+------+\n",
      "|_c0| city|         Item|country|month|    sales|city_|Item_|country_|month_|\n",
      "+---+-----+-------------+-------+-----+---------+-----+-----+--------+------+\n",
      "|  0|Abuja|  Butter Cake|Nigeria|    1| 723266.0|  1.0|  1.0|     0.0|   9.0|\n",
      "|  1|Abuja|  Butter Cake|Nigeria|    2| 630520.0|  1.0|  1.0|     0.0|  10.0|\n",
      "|  2|Abuja|  Butter Cake|Nigeria|    3| 692946.0|  1.0|  1.0|     0.0|   6.0|\n",
      "|  3|Abuja|  Butter Cake|Nigeria|    4| 714788.0|  1.0|  1.0|     0.0|  11.0|\n",
      "|  4|Abuja|  Butter Cake|Nigeria|    5| 720920.0|  1.0|  1.0|     0.0|   7.0|\n",
      "|  5|Abuja|  Butter Cake|Nigeria|    6| 553146.0|  1.0|  1.0|     0.0|   8.0|\n",
      "|  6|Abuja|  Butter Cake|Nigeria|    7| 742040.0|  1.0|  1.0|     0.0|   3.0|\n",
      "|  7|Abuja|  Butter Cake|Nigeria|    8| 944060.0|  1.0|  1.0|     0.0|   4.0|\n",
      "|  8|Abuja|  Butter Cake|Nigeria|    9| 867996.0|  1.0|  1.0|     0.0|   5.0|\n",
      "|  9|Abuja|  Butter Cake|Nigeria|   10| 831078.0|  1.0|  1.0|     0.0|   0.0|\n",
      "| 10|Abuja|  Butter Cake|Nigeria|   11| 747806.0|  1.0|  1.0|     0.0|   1.0|\n",
      "| 11|Abuja|  Butter Cake|Nigeria|   12| 790578.0|  1.0|  1.0|     0.0|   2.0|\n",
      "| 12|Abuja|Club Sandwich|Nigeria|    7|    560.0|  1.0|  4.0|     0.0|   3.0|\n",
      "| 13|Abuja|Club Sandwich|Nigeria|    8|      0.0|  1.0|  4.0|     0.0|   4.0|\n",
      "| 14|Abuja|Club Sandwich|Nigeria|    9|      0.0|  1.0|  4.0|     0.0|   5.0|\n",
      "| 15|Abuja|Club Sandwich|Nigeria|   10|    460.0|  1.0|  4.0|     0.0|   0.0|\n",
      "| 16|Abuja|Club Sandwich|Nigeria|   11|   2908.0|  1.0|  4.0|     0.0|   1.0|\n",
      "| 17|Abuja|Club Sandwich|Nigeria|   12|   2536.0|  1.0|  4.0|     0.0|   2.0|\n",
      "| 18|Abuja|     Doughnut|Nigeria|    1|1546638.0|  1.0|  2.0|     0.0|   9.0|\n",
      "| 19|Abuja|     Doughnut|Nigeria|    2|1255042.0|  1.0|  2.0|     0.0|  10.0|\n",
      "+---+-----+-------------+-------+-----+---------+-----+-----+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " indexer=StringIndexer(inputCols=['city', 'Item', 'country', 'month'],outputCols=['city_', 'Item_', 'country_', 'month_'])\n",
    "df_r=indexer.fit(df).transform(df)\n",
    "df_r.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'city',\n",
       " 'Item',\n",
       " 'country',\n",
       " 'month',\n",
       " 'sales',\n",
       " 'city_',\n",
       " 'Item_',\n",
       " 'country_',\n",
       " 'month_']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureassembler=VectorAssembler(inputCols=['city_','Item_','country_','month_'],\n",
    "                                 outputCol=\"Independent Features\")\n",
    "output=featureassembler.transform(df_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|Independent Features|\n",
      "+--------------------+\n",
      "|   [1.0,1.0,0.0,9.0]|\n",
      "|  [1.0,1.0,0.0,10.0]|\n",
      "|   [1.0,1.0,0.0,6.0]|\n",
      "|  [1.0,1.0,0.0,11.0]|\n",
      "|   [1.0,1.0,0.0,7.0]|\n",
      "|   [1.0,1.0,0.0,8.0]|\n",
      "|   [1.0,1.0,0.0,3.0]|\n",
      "|   [1.0,1.0,0.0,4.0]|\n",
      "|   [1.0,1.0,0.0,5.0]|\n",
      "|   [1.0,1.0,0.0,0.0]|\n",
      "|   [1.0,1.0,0.0,1.0]|\n",
      "|   [1.0,1.0,0.0,2.0]|\n",
      "|   [1.0,4.0,0.0,3.0]|\n",
      "|   [1.0,4.0,0.0,4.0]|\n",
      "|   [1.0,4.0,0.0,5.0]|\n",
      "|   [1.0,4.0,0.0,0.0]|\n",
      "|   [1.0,4.0,0.0,1.0]|\n",
      "|   [1.0,4.0,0.0,2.0]|\n",
      "|   [1.0,2.0,0.0,9.0]|\n",
      "|  [1.0,2.0,0.0,10.0]|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " output.select('Independent Features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=output.select(\"Independent Features\",\"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|Independent Features|    sales|\n",
      "+--------------------+---------+\n",
      "|   [1.0,1.0,0.0,9.0]| 723266.0|\n",
      "|  [1.0,1.0,0.0,10.0]| 630520.0|\n",
      "|   [1.0,1.0,0.0,6.0]| 692946.0|\n",
      "|  [1.0,1.0,0.0,11.0]| 714788.0|\n",
      "|   [1.0,1.0,0.0,7.0]| 720920.0|\n",
      "|   [1.0,1.0,0.0,8.0]| 553146.0|\n",
      "|   [1.0,1.0,0.0,3.0]| 742040.0|\n",
      "|   [1.0,1.0,0.0,4.0]| 944060.0|\n",
      "|   [1.0,1.0,0.0,5.0]| 867996.0|\n",
      "|   [1.0,1.0,0.0,0.0]| 831078.0|\n",
      "|   [1.0,1.0,0.0,1.0]| 747806.0|\n",
      "|   [1.0,1.0,0.0,2.0]| 790578.0|\n",
      "|   [1.0,4.0,0.0,3.0]|    560.0|\n",
      "|   [1.0,4.0,0.0,4.0]|      0.0|\n",
      "|   [1.0,4.0,0.0,5.0]|      0.0|\n",
      "|   [1.0,4.0,0.0,0.0]|    460.0|\n",
      "|   [1.0,4.0,0.0,1.0]|   2908.0|\n",
      "|   [1.0,4.0,0.0,2.0]|   2536.0|\n",
      "|   [1.0,2.0,0.0,9.0]|1546638.0|\n",
      "|  [1.0,2.0,0.0,10.0]|1255042.0|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "##train test split and train model\n",
    "train_data,test_data=data.randomSplit([0.75,0.25])\n",
    "regressor=LinearRegression(featuresCol='Independent Features', labelCol='sales')\n",
    "regressor=regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-2093506.8185, -10290531.0055, 22302426.7245, -13627.2784])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35975073.09042397"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking performance of model\n",
    "pred_results=regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/anaconda3/lib/python3.8/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+\n",
      "|Independent Features|              sales|          prediction|\n",
      "+--------------------+-------------------+--------------------+\n",
      "|           (4,[],[])|        8.7177846E7| 3.597507309042397E7|\n",
      "|       (4,[0],[7.0])|        2.6426778E7| 2.132052536058117E7|\n",
      "|       (4,[1],[1.0])|        1.4002136E7|2.5684542084882386E7|\n",
      "|       (4,[1],[3.0])|          5121848.0|   5103480.073799215|\n",
      "|       (4,[3],[6.0])|        7.3480204E7| 3.589330941979257E7|\n",
      "|       (4,[3],[9.0])|6.514119560000001E7|3.5852427584476866E7|\n",
      "|  [0.0,1.0,0.0,10.0]|        1.6738818E7|2.5548269300496712E7|\n",
      "|   [0.0,2.0,0.0,2.0]|        3.0316182E7|1.5366756522463664E7|\n",
      "|   [0.0,2.0,0.0,8.0]|        3.1336188E7|1.5284992851832263E7|\n",
      "|  [0.0,2.0,0.0,10.0]|        2.7335268E7|1.5257738294955127E7|\n",
      "|  [0.0,2.0,0.0,11.0]|        2.8626172E7|1.5244111016516563E7|\n",
      "|   [0.0,3.0,0.0,2.0]|          3512558.0|   5076225.516922079|\n",
      "|   [0.0,3.0,0.0,6.0]|          2809872.0|    5021716.40316781|\n",
      "|  [0.0,3.0,0.0,11.0]|          3878408.0|   4953580.010974977|\n",
      "|   [0.0,4.0,0.0,2.0]|             7590.0|  -5214305.488619506|\n",
      "|   [0.0,4.0,0.0,5.0]|                0.0|  -5255187.323935203|\n",
      "|   [1.0,0.0,0.0,8.0]|          5630852.0|3.3772548044366464E7|\n",
      "|   [1.0,1.0,0.0,1.0]|           747806.0|2.3577407987894848E7|\n",
      "|   [1.0,1.0,0.0,5.0]|           867996.0|2.3522898874140576E7|\n",
      "|   [1.0,1.0,0.0,7.0]|           720920.0|2.3495644317263443E7|\n",
      "+--------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Final comparison\n",
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.351039423233261, 14897523.069947043, 686565640724516.6)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### PErformance Metrics\n",
    "pred_results.r2,pred_results.meanAbsoluteError,pred_results.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
